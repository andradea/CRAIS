{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark as ps\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.driver.memory', '3g')\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '3g')\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"word2vec\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(c):\n",
    "    c = lower(c)\n",
    "    c = regexp_replace(c, \"^rt \", \"\")\n",
    "    c = regexp_replace(c, \"(https?\\://)\\S+\", \"\")\n",
    "    c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
    "#     c = regexp_replace(c, \"[0-9]\", \"\")\n",
    "    c = split(c, \"\\\\s+\") # tokenization...\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andradea/Documents/cr-engine/datasets/ASAP/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if 'CR' in f and '.csv' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[0]\n",
    "df = spark.read.csv(path + file, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(clean_text(col(\"response\")).alias(\"response\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            response|\n",
      "+--------------------+\n",
      "|[white, a, white,...|\n",
      "|[dark, gray, i, w...|\n",
      "|[black, black, be...|\n",
      "|[white, painting,...|\n",
      "|[dark, gray, i, t...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|    word|              vector|\n",
      "+--------+--------------------+\n",
      "|    rate|[0.68907362222671...|\n",
      "|      45|[-895507.4375,-92...|\n",
      "|    rage|[-18434.92578125,...|\n",
      "| absorbs|[-1.353594175488E...|\n",
      "|  egrees|[-0.2343023121356...|\n",
      "|     est|[118.70458984375,...|\n",
      "|    ound|[566.875793457031...|\n",
      "|perature|[-12.729274749755...|\n",
      "|    used|[-1.136143488E9,9...|\n",
      "|     eye|[0.33923476934432...|\n",
      "|averages|[3102.23510742187...|\n",
      "|  rature|[0.54148471355438...|\n",
      "|       e|[1.32436202409164...|\n",
      "| obsorbs|[-0.3662510812282...|\n",
      "|     snt|[-0.8332204818725...|\n",
      "|      se|[-9.819492E7,-2.7...|\n",
      "|    down|[25409.896484375,...|\n",
      "|  doghou|[-134.966796875,2...|\n",
      "|    side|[-6.2198796E7,-2....|\n",
      "|    4143|[0.58533424139022...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Learn a mapping from words to Vectors.\n",
    "word2Vec = Word2Vec(vectorSize=150, minCount=1, numPartitions=400, stepSize=0.025, maxIter=10, seed=42, \n",
    "                    windowSize=5, maxSentenceLength=1000, inputCol=\"response\", outputCol=\"result\")\n",
    "model = word2Vec.fit(df)\n",
    "model.getVectors().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = model.getVectors().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index\n",
    "word_index = {}\n",
    "for i in range(word_vector.word.count()):\n",
    "    word_index[word_vector.iloc[i, 0]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_index\n",
    "embeddings_index = {}\n",
    "for i in range(word_vector.vector.count()):\n",
    "    embeddings_index[i] = word_vector.iloc[i, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, len(embeddings_index[0])))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(i)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = '/Users/andradea/Documents/GitHub/CRAIS/Embeddings/'\n",
    "\n",
    "with open(path_save + 'word_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(path_save + 'embeddings_index.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_index, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
