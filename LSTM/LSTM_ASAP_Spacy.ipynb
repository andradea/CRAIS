{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import datetime \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg', disable=['parser', 'tagger', 'ner'])\n",
    "# nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASAP_CR10.csv',\n",
       " 'ASAP_CR9.csv',\n",
       " 'ASAP_CR8.csv',\n",
       " 'ASAP_CR3.csv',\n",
       " 'ASAP_CR2.csv',\n",
       " 'ASAP_CR1.csv',\n",
       " 'ASAP_CR5.csv',\n",
       " 'ASAP_CR4.csv',\n",
       " 'ASAP_CR6.csv',\n",
       " 'ASAP_CR7.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/andradea/Documents/cr-engine/datasets/ASAP/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if 'CR' in f and '.csv' in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASAP_CR1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>score_d1</th>\n",
       "      <th>r1_d1</th>\n",
       "      <th>r2_d1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASAP_CR1</td>\n",
       "      <td>ASAP_CR1_1</td>\n",
       "      <td>First I would add that the students might want...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASAP_CR1</td>\n",
       "      <td>ASAP_CR1_2</td>\n",
       "      <td>In the procedure, the group of students said t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item          id                                           response  \\\n",
       "0  ASAP_CR1  ASAP_CR1_1  First I would add that the students might want...   \n",
       "1  ASAP_CR1  ASAP_CR1_2  In the procedure, the group of students said t...   \n",
       "\n",
       "   score_d1  r1_d1  r2_d1  \n",
       "0         1      1      0  \n",
       "1         1      1      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[5]\n",
    "print(file)\n",
    "df = pd.read_csv(path + file)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = df.response.tolist()\n",
    "labels = df.score_d1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for response in responses:\n",
    "    length.append(len(nlp(response)))\n",
    "int(np.ceil(np.mean(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "max_len = int(np.ceil(np.mean(length)))\n",
    "vec_size = 300\n",
    "num_classes = len(df.score_d1.value_counts())\n",
    "print('number of classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 54, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_embedded = np.zeros((len(responses), max_len, vec_size))\n",
    "\n",
    "for i,response in enumerate(responses): \n",
    "    response = nlp(response)\n",
    "    for j,word in enumerate(response):\n",
    "        if j < max_len:\n",
    "            response_embedded[i][j] = word.vector\n",
    "\n",
    "response_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = to_categorical(labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 300\n",
      "testing size: 100\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(response_embedded, one_hot_labels, test_size=0.25, random_state=42)\n",
    "print('training size:', train_x.shape[0])\n",
    "print('testing size:', test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(max_len, vec_size))) # returns a sequence of vectors of dimension 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True))) # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(1024)) # return a single vector\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.01]\n",
    "epochs = 10000\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/10000\n",
      "300/300 [==============================] - 76s 253ms/step - loss: 1.3643 - acc: 0.3200 - val_loss: 1.4531 - val_acc: 0.2800\n",
      "Epoch 2/10000\n",
      "300/300 [==============================] - 71s 236ms/step - loss: 1.3583 - acc: 0.3000 - val_loss: 1.4230 - val_acc: 0.2800\n",
      "Epoch 3/10000\n",
      "300/300 [==============================] - 71s 238ms/step - loss: 1.3934 - acc: 0.3033 - val_loss: 1.3885 - val_acc: 0.2800\n",
      "Epoch 4/10000\n",
      "300/300 [==============================] - 71s 238ms/step - loss: 1.3951 - acc: 0.3200 - val_loss: 1.3880 - val_acc: 0.2800\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, \n",
    "                            epsilon=None, amsgrad=True, clipvalue=0.5)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "callbacks = [EarlyStopping(monitor='val_loss', min_delta=0.001, verbose=1)]\n",
    "history = model.fit(train_x, train_y, batch_size=batch_size, \n",
    "                    epochs=epochs, validation_data=(test_x, test_y), \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training error:', 1 - max(history.history['acc']), 'validation error:', 1- max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(train_x)\n",
    "train_k = cohen_kappa_score(pd.DataFrame(train_y).idxmax(axis=1), \n",
    "                            pd.DataFrame(train_pred).idxmax(axis=1), \n",
    "                            weights='quadratic')\n",
    "test_pred = model.predict(test_x)\n",
    "test_k = cohen_kappa_score(pd.DataFrame(test_y).idxmax(axis=1), \n",
    "                            pd.DataFrame(test_pred).idxmax(axis=1), \n",
    "                            weights='quadratic')\n",
    "\n",
    "print('training kappa:', train_k, 'validation kappa:', test_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = '/Users/alejandro/Documents/GitHub/CRAIS/LSTM/'\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "model.save(path_write + 'LSTM_Model_ASAP_' + file.split('.csv')[0] + '_' + timestamp + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
