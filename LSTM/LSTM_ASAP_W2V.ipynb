{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read = '/Users/andradea/Documents/GitHub/CRAIS/Embeddings/'\n",
    "\n",
    "with open(path_read + 'word_index.pkl', 'rb') as f:\n",
    "    word_index = pickle.load(f)\n",
    "\n",
    "with open(path_read + 'embeddings_index.pkl', 'rb') as f:\n",
    "    embeddings_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andradea/Documents/cr-engine/datasets/ASAP/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if 'CR' in f and '.csv' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>score_d1</th>\n",
       "      <th>r1_d1</th>\n",
       "      <th>r2_d1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASAP_CR10</td>\n",
       "      <td>ASAP_CR10_1</td>\n",
       "      <td>white ::  A white colored doghouse will make t...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASAP_CR10</td>\n",
       "      <td>ASAP_CR10_2</td>\n",
       "      <td>dark gray :: i would go with dark gray, so tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item           id                                           response  \\\n",
       "0  ASAP_CR10  ASAP_CR10_1  white ::  A white colored doghouse will make t...   \n",
       "1  ASAP_CR10  ASAP_CR10_2  dark gray :: i would go with dark gray, so tha...   \n",
       "\n",
       "   score_d1  r1_d1  r2_d1  \n",
       "0         2      2      2  \n",
       "1         1      1      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[0]\n",
    "df = pd.read_csv(path + file)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = df.response.tolist()\n",
    "labels = df.score_d1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(c):\n",
    "    c = c.lower()\n",
    "#     c = re.subn(\"^rt \", \"\", c)\n",
    "    c = re.sub(\"\\W\", \" \", c)\n",
    "#     c = regexp_replace(c, \"[0-9]\", \"\")\n",
    "    c = re.sub(\"\\s\\s+\", \" \", c)\n",
    "    c = c.split(' ') # tokenization...\n",
    "\n",
    "    return c\n",
    "\n",
    "length = []\n",
    "for response in responses:\n",
    "    response = clean_text(response)\n",
    "    length.append(len(response))\n",
    "int(np.ceil(np.mean(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = int(np.ceil(np.mean(length)))\n",
    "vec_size = 150\n",
    "num_classes = len(df.score_d1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 43, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_embedded = np.zeros((len(responses), max_len, vec_size))\n",
    "\n",
    "for i,response in enumerate(responses): \n",
    "    response = clean_text(response)\n",
    "    for j,word in enumerate(response):\n",
    "        if j < max_len:\n",
    "            if word in vocabulary:\n",
    "                idx = word_index[word]\n",
    "                response_embedded[i][j] = embeddings_index[idx]\n",
    "\n",
    "response_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = to_categorical(labels, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 300\n",
      "testing size: 100\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(response_embedded, one_hot_labels, test_size=0.25, random_state=42)\n",
    "print('training size:', train_x.shape[0])\n",
    "print('testing size:', test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(max_len, vec_size))) # returns a sequence of vectors of dimension 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True))) # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256)) # return a single vector of dimension 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.01]\n",
    "epochs = 100\n",
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 8s 26ms/step - loss: 1.4906 - acc: 0.4433 - val_loss: 2.2148 - val_acc: 0.3800\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 1.1528 - acc: 0.5067 - val_loss: 1.3626 - val_acc: 0.5200\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 1.0242 - acc: 0.5767 - val_loss: 0.9146 - val_acc: 0.5600\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.9230 - acc: 0.5800 - val_loss: 1.3835 - val_acc: 0.3900\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.9129 - acc: 0.6267 - val_loss: 1.1133 - val_acc: 0.4100\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.9364 - acc: 0.5900 - val_loss: 1.1531 - val_acc: 0.5400\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 4s 15ms/step - loss: 0.9457 - acc: 0.5767 - val_loss: 0.9420 - val_acc: 0.4700\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8972 - acc: 0.6100 - val_loss: 0.9041 - val_acc: 0.5800\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8967 - acc: 0.5667 - val_loss: 1.0833 - val_acc: 0.5900\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8828 - acc: 0.6233 - val_loss: 0.9483 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8824 - acc: 0.6067 - val_loss: 0.9375 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.9032 - acc: 0.6367 - val_loss: 0.9887 - val_acc: 0.6000\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8241 - acc: 0.6400 - val_loss: 1.0165 - val_acc: 0.5400\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8619 - acc: 0.6500 - val_loss: 0.9133 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8177 - acc: 0.6400 - val_loss: 0.9316 - val_acc: 0.5900\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7724 - acc: 0.6600 - val_loss: 0.9615 - val_acc: 0.6200\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7974 - acc: 0.6833 - val_loss: 0.9001 - val_acc: 0.5200\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7486 - acc: 0.6733 - val_loss: 0.9507 - val_acc: 0.5500\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7551 - acc: 0.6633 - val_loss: 1.1061 - val_acc: 0.5800\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8382 - acc: 0.6367 - val_loss: 1.0207 - val_acc: 0.5100\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7876 - acc: 0.6333 - val_loss: 1.7155 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7907 - acc: 0.6633 - val_loss: 1.0000 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8214 - acc: 0.6567 - val_loss: 0.8619 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8465 - acc: 0.6267 - val_loss: 0.9484 - val_acc: 0.6100\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8119 - acc: 0.6533 - val_loss: 1.5484 - val_acc: 0.3900\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7623 - acc: 0.6833 - val_loss: 1.7309 - val_acc: 0.4700\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7871 - acc: 0.6967 - val_loss: 1.3426 - val_acc: 0.4500\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7638 - acc: 0.6733 - val_loss: 1.0120 - val_acc: 0.5700\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7349 - acc: 0.7000 - val_loss: 0.9036 - val_acc: 0.5800\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7226 - acc: 0.7067 - val_loss: 1.0705 - val_acc: 0.5500\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.8459 - acc: 0.6300 - val_loss: 0.8297 - val_acc: 0.6100\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7693 - acc: 0.6467 - val_loss: 1.2762 - val_acc: 0.4600\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7979 - acc: 0.6733 - val_loss: 0.8536 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.9034 - acc: 0.6233 - val_loss: 0.8715 - val_acc: 0.6100\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8170 - acc: 0.6567 - val_loss: 1.4812 - val_acc: 0.5100\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7661 - acc: 0.6767 - val_loss: 3.6752 - val_acc: 0.3900\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8119 - acc: 0.6900 - val_loss: 1.2876 - val_acc: 0.4500\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7526 - acc: 0.6767 - val_loss: 0.8469 - val_acc: 0.6100\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7794 - acc: 0.6700 - val_loss: 0.8566 - val_acc: 0.5900\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.8265 - acc: 0.6300 - val_loss: 0.8814 - val_acc: 0.5800\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.8084 - acc: 0.6867 - val_loss: 0.9268 - val_acc: 0.5800\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7748 - acc: 0.6600 - val_loss: 1.1124 - val_acc: 0.5600\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7662 - acc: 0.6767 - val_loss: 0.9851 - val_acc: 0.5200\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7948 - acc: 0.6600 - val_loss: 1.4291 - val_acc: 0.4600\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8047 - acc: 0.6500 - val_loss: 0.8121 - val_acc: 0.5300\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8032 - acc: 0.6567 - val_loss: 0.9879 - val_acc: 0.5600\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7328 - acc: 0.7000 - val_loss: 2.1012 - val_acc: 0.3900\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7539 - acc: 0.6900 - val_loss: 1.4943 - val_acc: 0.4400\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7510 - acc: 0.6933 - val_loss: 2.0436 - val_acc: 0.3900\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.7619 - acc: 0.6833 - val_loss: 2.2385 - val_acc: 0.3900\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7595 - acc: 0.7200 - val_loss: 1.1876 - val_acc: 0.6200\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7737 - acc: 0.6733 - val_loss: 0.8665 - val_acc: 0.6100\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8668 - acc: 0.6067 - val_loss: 2.7093 - val_acc: 0.2700\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8373 - acc: 0.6433 - val_loss: 5.8247 - val_acc: 0.2800\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8633 - acc: 0.6467 - val_loss: 0.9004 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8101 - acc: 0.6533 - val_loss: 1.0132 - val_acc: 0.5600\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7779 - acc: 0.6667 - val_loss: 0.8840 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8307 - acc: 0.6467 - val_loss: 0.8583 - val_acc: 0.5800\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7379 - acc: 0.6867 - val_loss: 1.2144 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7653 - acc: 0.6633 - val_loss: 1.2355 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8425 - acc: 0.6367 - val_loss: 0.8948 - val_acc: 0.5400\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7996 - acc: 0.6533 - val_loss: 0.8603 - val_acc: 0.5800\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8186 - acc: 0.6600 - val_loss: 0.9216 - val_acc: 0.5400\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8816 - acc: 0.6367 - val_loss: 0.8375 - val_acc: 0.6100\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8257 - acc: 0.6167 - val_loss: 0.8413 - val_acc: 0.6200\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7643 - acc: 0.6533 - val_loss: 0.8411 - val_acc: 0.5800\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8347 - acc: 0.6400 - val_loss: 0.9673 - val_acc: 0.5700\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8110 - acc: 0.6367 - val_loss: 0.8114 - val_acc: 0.6500\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7884 - acc: 0.6533 - val_loss: 0.8430 - val_acc: 0.6200\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7559 - acc: 0.6833 - val_loss: 3.4933 - val_acc: 0.3900\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7996 - acc: 0.6733 - val_loss: 1.7035 - val_acc: 0.4400\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7932 - acc: 0.6600 - val_loss: 1.6795 - val_acc: 0.4900\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8205 - acc: 0.6533 - val_loss: 2.5629 - val_acc: 0.4200\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8118 - acc: 0.6700 - val_loss: 1.8819 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8195 - acc: 0.6367 - val_loss: 3.5256 - val_acc: 0.3900\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8308 - acc: 0.6400 - val_loss: 4.3184 - val_acc: 0.3900\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8707 - acc: 0.6267 - val_loss: 2.5568 - val_acc: 0.2600\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8465 - acc: 0.6067 - val_loss: 1.0475 - val_acc: 0.5900\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 4s 15ms/step - loss: 0.8187 - acc: 0.6200 - val_loss: 1.2798 - val_acc: 0.3800\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8190 - acc: 0.6167 - val_loss: 1.0035 - val_acc: 0.5900\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8068 - acc: 0.6567 - val_loss: 0.8298 - val_acc: 0.5300\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7959 - acc: 0.6333 - val_loss: 0.8915 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8090 - acc: 0.6500 - val_loss: 0.8252 - val_acc: 0.6100\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7916 - acc: 0.6700 - val_loss: 0.8154 - val_acc: 0.5800\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8195 - acc: 0.6400 - val_loss: 0.8513 - val_acc: 0.5800\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7739 - acc: 0.6500 - val_loss: 0.8475 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8225 - acc: 0.6467 - val_loss: 0.9065 - val_acc: 0.5800\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8576 - acc: 0.6033 - val_loss: 0.9852 - val_acc: 0.5600\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7746 - acc: 0.6667 - val_loss: 0.9395 - val_acc: 0.5900\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7794 - acc: 0.6400 - val_loss: 1.3562 - val_acc: 0.5500\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8658 - acc: 0.6233 - val_loss: 0.9091 - val_acc: 0.5600\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8247 - acc: 0.6533 - val_loss: 0.8896 - val_acc: 0.5800\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7834 - acc: 0.6533 - val_loss: 0.7793 - val_acc: 0.6700\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.8106 - acc: 0.6333 - val_loss: 1.3045 - val_acc: 0.5100\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7538 - acc: 0.6633 - val_loss: 1.2676 - val_acc: 0.5400\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7866 - acc: 0.6467 - val_loss: 1.8020 - val_acc: 0.4100\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7600 - acc: 0.6667 - val_loss: 2.6564 - val_acc: 0.3900\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7326 - acc: 0.6833 - val_loss: 1.7183 - val_acc: 0.4300\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7728 - acc: 0.6567 - val_loss: 1.8731 - val_acc: 0.3900\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.7692 - acc: 0.6567 - val_loss: 1.3645 - val_acc: 0.4200\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.28 validation error: 0.3299999868869782\n"
     ]
    }
   ],
   "source": [
    "print('training error:', 1 - max(history.history['acc']), 'validation error:', 1 ß- max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training kappa: 0.09963627690656485 validation kappa: 0.04423380726698267\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(train_x)\n",
    "train_k = cohen_kappa_score(pd.DataFrame(train_y).idxmax(axis=1), \n",
    "                            pd.DataFrame(train_pred).idxmax(axis=1), \n",
    "                            weights='quadratic')\n",
    "test_pred = model.predict(test_x)\n",
    "test_k = cohen_kappa_score(pd.DataFrame(test_y).idxmax(axis=1), \n",
    "                            pd.DataFrame(test_pred).idxmax(axis=1), \n",
    "                            weights='quadratic')\n",
    "\n",
    "print('training kappa:', train_k, 'validation kappa:', test_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
